{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary packages\n",
    "import requests\n",
    "from requests_html import AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import warnings \n",
    "from details import agt, cook\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the base url  \n",
    "base_url = 'https://www.realtytrac.com/'\n",
    "\n",
    "#Create a search for the LA area\n",
    "la_search = 'mapsearch/sold/ca/los-angeles-county/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab the website content and store it in a BeautifulSoup object\n",
    "response = requests.get(base_url+la_search, headers=agt, cookies=cook)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You'll scrape 2000 houses\n"
     ]
    }
   ],
   "source": [
    "houses = soup.find_all('div', class_=\"house alt clearfix\")\n",
    "\n",
    "#Number of pages to run the scraper through\n",
    "num_pages = 200\n",
    "\n",
    "print(f'You\\'ll scrape {len(houses)*num_pages} houses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absolute_links = []\n",
    "\n",
    "for i in range(num_pages):\n",
    "    page = soup.find_all('div', class_=\"house alt clearfix\")\n",
    "    \n",
    "    for house in page:\n",
    "        absolute_links.append(base_url+house.find('a')['href'])\n",
    "    \n",
    "    next_link = soup.find('a', class_='next')['href']\n",
    "    response = requests.get(base_url+next_link, headers=agt, cookies=cook)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "len(absolute_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create the function that extracts the attributes for each house(link)\n",
    "\n",
    "#details_df = pd.DataFrame()\n",
    "\n",
    "def find_details(house):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        lat = house.find('meta', property='og:latitude')['content']\n",
    "    except:\n",
    "        lat=None\n",
    "    try:\n",
    "        long = house.find('meta', property='og:longitude')['content'] \n",
    "    except:\n",
    "        long=None\n",
    "    try:    \n",
    "        address = house.find('span', class_='address heading').text \n",
    "    except:\n",
    "        address=None\n",
    "    \n",
    "    #Property Details\n",
    "    try:\n",
    "        details = house.find('ul', class_='detail-list')\n",
    "    except:\n",
    "        details = None\n",
    "    try:\n",
    "        add_details = details.find_all('li')\n",
    "    except:\n",
    "        add_details = None\n",
    "    \n",
    "    try:\n",
    "        prop_type = add_details[0].find('span', itemprop='name').text\n",
    "    except:\n",
    "        prop_type=None\n",
    "    try:\n",
    "        rooms = add_details[1].find('span', itemprop='description').text\n",
    "    except:\n",
    "        rooms=None\n",
    "    try:\n",
    "        home_size_p = details.find('span', itemprop='name', text='Home Size').parent\n",
    "        home_size = home_size_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        home_size=''\n",
    "    try:                                                              \n",
    "        home_unit = home_size_p.find('span', itemprop='unitText').text\n",
    "    except:\n",
    "        home_unit=''\n",
    "    try:\n",
    "        lot_size_p = details.find('span', itemprop='name', text='Lot Size').parent\n",
    "        lot_size = lot_size_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        lot_size=''\n",
    "    try:                                                             \n",
    "        lot_unit = lot_size_p.find('span', itemprop='unitText').text\n",
    "    except:\n",
    "        lot_unit=''\n",
    "    try:\n",
    "        year_built_p = details.find('span', itemprop='description', text='Built in').parent\n",
    "        year_built = year_built_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        year_built=None\n",
    "    try:\n",
    "        parcel_p = details.find('span', itemprop='name', text='Parcel Number').parent\n",
    "        parcel = parcel_p.find('span', itemprop='propertyID').text\n",
    "    except:\n",
    "        parcel=None\n",
    "    try:\n",
    "        realty_p = details.find('span', itemprop='name', text='RealtyTrac Property ID').parent\n",
    "        realty = realty_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        realty=None\n",
    "    try:\n",
    "        county_p = details.find('span', itemprop='name', text='County').parent\n",
    "        county = county_p.find('span', itemprop='description').text\n",
    "    except:\n",
    "        county=None\n",
    "    try:\n",
    "        sub_p = details.find('span', itemprop='name', text='Subdivision').parent\n",
    "        sub = sub_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        sub=None\n",
    "    try:\n",
    "        census_p = details.find('span', itemprop='name', text='Census').parent\n",
    "        census = census_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        census=None\n",
    "    try:\n",
    "        tract_p = details.find('span', itemprop='name', text='Tract').parent\n",
    "        tract = tract_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        tract=None\n",
    "    try:\n",
    "        zoning = details.find_all('li')[-2].text\n",
    "    except:\n",
    "        zoning=None\n",
    "    try:                                                             \n",
    "        lot_p = details.find('span', itemprop='name', text='Lot').parent\n",
    "        lot = lot_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        lot = None\n",
    "    \n",
    "    \n",
    "    #Sales History\n",
    "    try:\n",
    "        sales = house.find('section', id='occupancy-link') \n",
    "    except:\n",
    "        sales = None\n",
    "    \n",
    "    try:                                                              \n",
    "        sale_price = sales.find('label', attrs={'for':'PurchasePrice'}).parent.parent.find('td', class_='col2').text            \n",
    "    except:\n",
    "        sale_price=None\n",
    "    try:\n",
    "        date = sales.find('label', attrs={'for':'PurchaseDate'}).parent.parent.find('td', class_='col2').text\n",
    "    except:\n",
    "        date=None\n",
    "    \n",
    "    #Estimated Value\n",
    "    try:\n",
    "        est = house.find('div', class_='rate-row access')\n",
    "    except:\n",
    "        est = None\n",
    "    \n",
    "    try:                                                              \n",
    "        estimate = est.find('strong', class_='price').text\n",
    "    except:\n",
    "        estimate= None\n",
    "    \n",
    "    #Home Disclosures\n",
    "    try:\n",
    "        disc = house.find('div', id=\"collapsePropertyHomeDisclosuresArea\")\n",
    "    except:\n",
    "        disc = None\n",
    "    \n",
    "    try:\n",
    "        sex_offenders = disc.find('span', class_='hd-title', text='Sex Offenders').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        sex_offenders = None\n",
    "    \n",
    "    try:\n",
    "        crime_index = disc.find('span', class_='hd-title',text='Crime Index').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        crime_index = None\n",
    "    \n",
    "    try:\n",
    "        env_hazards = disc.find('span', class_='hd-title',text='Environmental Hazards').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        env_hazards = None\n",
    "    \n",
    "    try:\n",
    "        natural_disasters = disc.find('span', class_='hd-title', text = 'Natural Disasters').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        natural_disasters = None\n",
    "    try:\n",
    "        school_index = disc.find('span', class_='hd-title', text = 'Local Schools').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        school_index = None\n",
    "    \n",
    "    try:\n",
    "        url = house.find('meta', property='og:url')['content']\n",
    "    except:\n",
    "        url=None\n",
    "    #Create the df to be returned\n",
    "    details_df = pd.DataFrame({\n",
    "        \n",
    "                       'latitude': [lat],\n",
    "                       'longitude': [long],\n",
    "                       'address':[address],\n",
    "                       'property_type': [prop_type],\n",
    "                       'rooms': [rooms],\n",
    "                       'home_size': [home_size+home_unit],\n",
    "                       'lot_size': [lot_size+lot_unit],\n",
    "                       'year_built': [year_built],\n",
    "                       'parcel_number': [parcel],\n",
    "                       'realtyID': [realty],\n",
    "                       'county': [county],\n",
    "                       'subdivision': [sub],\n",
    "                       'census': [census],\n",
    "                       'tract': [tract],\n",
    "                       'lot': [lot],\n",
    "                       'zoning': [zoning],\n",
    "                       'date': [date],\n",
    "                       'sale_price': [sale_price],\n",
    "                       'estimated_value': [estimate],\n",
    "                       'sex_offenders': [sex_offenders],\n",
    "                       'crime_index': [crime_index],\n",
    "                       'enviornmental_hazards': [env_hazards],\n",
    "                       'natural_disasters': [natural_disasters],\n",
    "                       'school_quality': [school_index],\n",
    "                       'url': [url]\n",
    "                      })\n",
    "    \n",
    "    return details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that captures sales history data\n",
    "\n",
    "def find_sales_history(house):\n",
    "    \n",
    "    temp = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        details = house.find('ul', class_='detail-list')\n",
    "    except:\n",
    "        details = None\n",
    "   \n",
    "    try:\n",
    "        parcel_p = details.find('span', itemprop='name', text='Parcel Number').parent\n",
    "        parcel = parcel_p.find('span', itemprop='propertyID').text\n",
    "    except:\n",
    "        parcel=None\n",
    "    \n",
    "    try:\n",
    "        table = house.find('table', class_='sales-table history-table').find('tbody')\n",
    "    except:\n",
    "        table = None\n",
    "    \n",
    "    try:\n",
    "        sales = table.find_all('tr')\n",
    "    except:\n",
    "        sales = None\n",
    "    \n",
    "    if sales !=None:\n",
    "        \n",
    "        for i in range(len(sales)):\n",
    "            \n",
    "            try:\n",
    "                date = sales[i].find('td', class_='col-1').text\n",
    "            except:\n",
    "                date = None\n",
    "        \n",
    "            try:\n",
    "                price = sales[i].find('td', class_='col-3').text\n",
    "            except:\n",
    "                price = None\n",
    "            \n",
    "            try:\n",
    "                price_sqft = sales[i].find('td', class_='col-2').text\n",
    "            except:\n",
    "                price_sqft = None\n",
    "            \n",
    "        \n",
    "            details_df = pd.DataFrame({\n",
    "                \n",
    "                    'parcel_number': [parcel],\n",
    "                    'date': [date],\n",
    "                    'price': [price]\n",
    "                    #'price_sqft': [price_sqft]\n",
    "                   \n",
    "                      })\n",
    "            \n",
    "            temp = temp.append(details_df, ignore_index=True)\n",
    "            \n",
    "      \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spot check \n",
    "#df = pd.DataFrame()\n",
    "#asession = AsyncHTMLSession()\n",
    "#r = await asession.get(absolute_links[16])\n",
    "#await r.html.arender()\n",
    "#response = r.html.raw_html\n",
    "#soup = BeautifulSoup(response, 'html.parser')\n",
    "#df = df.append(find_sales_history(soup), ignore_index=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"links.txt\", \"w\") as f:\n",
    "    for s in absolute_links:\n",
    "        f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Opening up the links file and saving it as a list\n",
    "absolute_links = []\n",
    "\n",
    "with open(\"links.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        absolute_links.append(line.strip())\n",
    "        \n",
    "len(absolute_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 25 properties\n",
      "Scraped 50 properties\n",
      "Scraped 75 properties\n",
      "Scraped 100 properties\n",
      "Scraped 125 properties\n",
      "Scraped 150 properties\n",
      "Scraped 175 properties\n",
      "Scraped 200 properties\n",
      "Scraped 225 properties\n",
      "Scraped 250 properties\n",
      "Scraped 275 properties\n",
      "Scraped 300 properties\n",
      "Scraped 325 properties\n",
      "Scraped 350 properties\n",
      "Scraped 375 properties\n",
      "Scraped 400 properties\n",
      "Scraped 425 properties\n",
      "Scraped 450 properties\n",
      "Scraped 475 properties\n",
      "Scraped 500 properties\n",
      "Scraped 525 properties\n",
      "Scraped 550 properties\n",
      "Scraped 575 properties\n",
      "Scraped 600 properties\n",
      "Scraped 625 properties\n",
      "Scraped 650 properties\n",
      "Scraped 675 properties\n",
      "Scraped 700 properties\n",
      "Scraped 725 properties\n",
      "Scraped 750 properties\n",
      "Scraped 775 properties\n",
      "Scraped 800 properties\n",
      "Scraped 825 properties\n",
      "Scraped 850 properties\n",
      "Scraped 875 properties\n",
      "Scraped 900 properties\n",
      "Scraped 925 properties\n",
      "Scraped 950 properties\n",
      "Scraped 975 properties\n",
      "Scraped 1000 properties\n",
      "Scraped 1025 properties\n",
      "Scraped 1050 properties\n",
      "Scraped 1075 properties\n",
      "Scraped 1100 properties\n",
      "Scraped 1125 properties\n",
      "Scraped 1150 properties\n",
      "Scraped 1175 properties\n",
      "Scraped 1200 properties\n",
      "Scraped 1225 properties\n",
      "Scraped 1250 properties\n",
      "Scraped 1275 properties\n",
      "Scraped 1300 properties\n",
      "Scraped 1325 properties\n",
      "Scraped 1350 properties\n",
      "Scraped 1375 properties\n",
      "Scraped 1400 properties\n",
      "Scraped 1425 properties\n",
      "Scraped 1450 properties\n",
      "Scraped 1475 properties\n",
      "Scraped 1500 properties\n",
      "Scraped 1525 properties\n",
      "Scraped 1550 properties\n",
      "Scraped 1575 properties\n",
      "Scraped 1600 properties\n",
      "Scraped 1625 properties\n",
      "Scraped 1650 properties\n",
      "Scraped 1675 properties\n",
      "Scraped 1700 properties\n",
      "Scraped 1725 properties\n",
      "Scraped 1750 properties\n",
      "Scraped 1775 properties\n",
      "Scraped 1800 properties\n",
      "Scraped 1825 properties\n",
      "Scraped 1850 properties\n",
      "Scraped 1875 properties\n",
      "Scraped 1900 properties\n",
      "Scraped 1925 properties\n",
      "Scraped 1950 properties\n",
      "Scraped 1975 properties\n",
      "Scraped 2000 properties\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the houses captured in absolute_links\n",
    "details = pd.DataFrame()\n",
    "sales_history  = pd.DataFrame()\n",
    "asession = AsyncHTMLSession()\n",
    "\n",
    "\n",
    "for i in range(len(absolute_links)):\n",
    "    r = await asession.get(absolute_links[i])\n",
    "    await r.html.arender()\n",
    "    resp= r.html.raw_html\n",
    "    soup = BeautifulSoup(resp, 'html.parser')\n",
    "    details = details.append(find_details(soup), ignore_index=True)\n",
    "    sales_history = sales_history.append(find_sales_history(soup), ignore_index=True)\n",
    "\n",
    "    if (i+1)%25 == 0:\n",
    "        details.to_csv('Data/house_data_details_scraped.csv', index=False)\n",
    "        sales_history.to_csv('Data/house_data_saleshistory_scraped.csv', index=False)\n",
    "        print(f'Scraped {details.shape[0]} properties')\n",
    "        asession.close()\n",
    "        asession = AsyncHTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "      <th>property_type</th>\n",
       "      <th>rooms</th>\n",
       "      <th>home_size</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>year_built</th>\n",
       "      <th>parcel_number</th>\n",
       "      <th>realtyID</th>\n",
       "      <th>...</th>\n",
       "      <th>zoning</th>\n",
       "      <th>date</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>estimated_value</th>\n",
       "      <th>sex_offenders</th>\n",
       "      <th>crime_index</th>\n",
       "      <th>enviornmental_hazards</th>\n",
       "      <th>natural_disasters</th>\n",
       "      <th>school_quality</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.004865</td>\n",
       "      <td>-118.312134</td>\n",
       "      <td>1821 W 43rd Pl</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>2 beds, 1 bath</td>\n",
       "      <td>1,322 sqft</td>\n",
       "      <td>5,750 sqft</td>\n",
       "      <td>1915</td>\n",
       "      <td>5022007005</td>\n",
       "      <td>1113736589</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nZoning:\\n\\nLAR1\\n\\t\\t</td>\n",
       "      <td>12/14/2020</td>\n",
       "      <td>$743,000</td>\n",
       "      <td>$667,100</td>\n",
       "      <td>80 Found</td>\n",
       "      <td>Slightly High</td>\n",
       "      <td>7 Found</td>\n",
       "      <td>2 Found</td>\n",
       "      <td>Poor</td>\n",
       "      <td>https://www.realtytrac.com/property/ca/los-ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.208532</td>\n",
       "      <td>-118.228494</td>\n",
       "      <td>2315 Mira Vista Ave # 101</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>3 beds, 3 baths</td>\n",
       "      <td>1,460 sqft</td>\n",
       "      <td>9,003 sqft</td>\n",
       "      <td>2005</td>\n",
       "      <td>5807006114</td>\n",
       "      <td>1113736606</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nZoning:\\n\\nLCR3YY\\n\\t\\t</td>\n",
       "      <td>12/14/2020</td>\n",
       "      <td>$690,000</td>\n",
       "      <td>$691,500</td>\n",
       "      <td>0 Found</td>\n",
       "      <td>None</td>\n",
       "      <td>5 Found</td>\n",
       "      <td>0 Found</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>https://www.realtytrac.com/property/ca/montros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.177544</td>\n",
       "      <td>-118.515557</td>\n",
       "      <td>5864 Texhoma Ave</td>\n",
       "      <td>Single Family Residence</td>\n",
       "      <td>3 beds, 2 baths</td>\n",
       "      <td>1,444 sqft</td>\n",
       "      <td>5,500 sqft</td>\n",
       "      <td>1949</td>\n",
       "      <td>2254005028</td>\n",
       "      <td>1113737946</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nZoning:\\n\\nLAR1\\n\\t\\t</td>\n",
       "      <td>12/14/2020</td>\n",
       "      <td>$680,000</td>\n",
       "      <td>$556,300</td>\n",
       "      <td>3 Found</td>\n",
       "      <td>None</td>\n",
       "      <td>5 Found</td>\n",
       "      <td>1 Found</td>\n",
       "      <td>Average</td>\n",
       "      <td>https://www.realtytrac.com/property/ca/encino/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.171504</td>\n",
       "      <td>-118.22724</td>\n",
       "      <td>1635 N Verdugo Rd # A</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>2 beds, 3 baths</td>\n",
       "      <td>1,604 sqft</td>\n",
       "      <td>10,359 sqft</td>\n",
       "      <td>1978</td>\n",
       "      <td>5652006035</td>\n",
       "      <td>1113737947</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nZoning:\\n\\nGLR4-L*\\n\\t\\t</td>\n",
       "      <td>12/14/2020</td>\n",
       "      <td>$666,000</td>\n",
       "      <td>$735,300</td>\n",
       "      <td>0 Found</td>\n",
       "      <td>Low</td>\n",
       "      <td>5 Found</td>\n",
       "      <td>1 Found</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>https://www.realtytrac.com/property/ca/glendal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.01606</td>\n",
       "      <td>-118.174554</td>\n",
       "      <td>1309 S Eastern Ave</td>\n",
       "      <td>Warehouse, Storage</td>\n",
       "      <td>None</td>\n",
       "      <td>4,900 sqft</td>\n",
       "      <td>11,681 sqft</td>\n",
       "      <td>1955</td>\n",
       "      <td>5241012012</td>\n",
       "      <td>1113738480</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nZoning:\\n\\nCMM1*\\n\\t\\t</td>\n",
       "      <td>12/14/2020</td>\n",
       "      <td>$1,150,000</td>\n",
       "      <td>None</td>\n",
       "      <td>10 Found</td>\n",
       "      <td>High</td>\n",
       "      <td>18 Found</td>\n",
       "      <td>1 Found</td>\n",
       "      <td>Average</td>\n",
       "      <td>https://www.realtytrac.com/property/ca/commerc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude    longitude                    address            property_type  \\\n",
       "0  34.004865  -118.312134             1821 W 43rd Pl  Single Family Residence   \n",
       "1  34.208532  -118.228494  2315 Mira Vista Ave # 101              Condominium   \n",
       "2  34.177544  -118.515557           5864 Texhoma Ave  Single Family Residence   \n",
       "3  34.171504   -118.22724      1635 N Verdugo Rd # A              Condominium   \n",
       "4   34.01606  -118.174554         1309 S Eastern Ave       Warehouse, Storage   \n",
       "\n",
       "             rooms   home_size     lot_size year_built parcel_number  \\\n",
       "0   2 beds, 1 bath  1,322 sqft   5,750 sqft       1915    5022007005   \n",
       "1  3 beds, 3 baths  1,460 sqft   9,003 sqft       2005    5807006114   \n",
       "2  3 beds, 2 baths  1,444 sqft   5,500 sqft       1949    2254005028   \n",
       "3  2 beds, 3 baths  1,604 sqft  10,359 sqft       1978    5652006035   \n",
       "4             None  4,900 sqft  11,681 sqft       1955    5241012012   \n",
       "\n",
       "     realtyID  ...                      zoning        date  sale_price  \\\n",
       "0  1113736589  ...     \\nZoning:\\n\\nLAR1\\n\\t\\t  12/14/2020    $743,000   \n",
       "1  1113736606  ...   \\nZoning:\\n\\nLCR3YY\\n\\t\\t  12/14/2020    $690,000   \n",
       "2  1113737946  ...     \\nZoning:\\n\\nLAR1\\n\\t\\t  12/14/2020    $680,000   \n",
       "3  1113737947  ...  \\nZoning:\\n\\nGLR4-L*\\n\\t\\t  12/14/2020    $666,000   \n",
       "4  1113738480  ...    \\nZoning:\\n\\nCMM1*\\n\\t\\t  12/14/2020  $1,150,000   \n",
       "\n",
       "  estimated_value sex_offenders    crime_index enviornmental_hazards  \\\n",
       "0        $667,100      80 Found  Slightly High               7 Found   \n",
       "1        $691,500       0 Found           None               5 Found   \n",
       "2        $556,300       3 Found           None               5 Found   \n",
       "3        $735,300       0 Found            Low               5 Found   \n",
       "4            None      10 Found           High              18 Found   \n",
       "\n",
       "  natural_disasters school_quality  \\\n",
       "0           2 Found           Poor   \n",
       "1           0 Found      Excellent   \n",
       "2           1 Found        Average   \n",
       "3           1 Found      Excellent   \n",
       "4           1 Found        Average   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.realtytrac.com/property/ca/los-ang...  \n",
       "1  https://www.realtytrac.com/property/ca/montros...  \n",
       "2  https://www.realtytrac.com/property/ca/encino/...  \n",
       "3  https://www.realtytrac.com/property/ca/glendal...  \n",
       "4  https://www.realtytrac.com/property/ca/commerc...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the dataframe to a csv file\n",
    "details.to_csv('Data/house_data_details_scraped.csv', index=False)\n",
    "sales_history.to_csv('Data/house_data_saleshistory_scraped.csv', index=False)\n",
    "details.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
