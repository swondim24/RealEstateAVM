{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary packages\n",
    "import requests\n",
    "from requests_html import AsyncHTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/house_data_details_scraped.csv')\n",
    "scraped = list(df['parcel_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the base url  \n",
    "base_url = 'https://www.realtytrac.com/'\n",
    "\n",
    "#Create a search for the LA area\n",
    "la_search = 'mapsearch/sold/ca/los-angeles-county/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab the website content and store it in a BeautifulSoup object\n",
    "response = requests.get(base_url+la_search, headers=agent, cookies=cookies)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You'll scrape 5000 houses\n"
     ]
    }
   ],
   "source": [
    "houses = soup.find_all('div', class_=\"house alt clearfix\")\n",
    "\n",
    "#Number of pages to run the scraper through\n",
    "num_pages = 500\n",
    "\n",
    "print(f'You\\'ll scrape {len(houses)*num_pages} houses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absolute_links = []\n",
    "\n",
    "for i in range(num_pages):\n",
    "    page = soup.find_all('div', class_=\"house alt clearfix\")\n",
    "    \n",
    "    for house in page:\n",
    "        absolute_links.append(base_url+house.find('a')['href'])\n",
    "    \n",
    "    next_link = soup.find('a', class_='next')['href']\n",
    "    response = requests.get(base_url+next_link, headers=agent, cookies=cookies)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "len(absolute_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create the function that extracts the attributes for each house(link)\n",
    "\n",
    "details_df = pd.DataFrame()\n",
    "\n",
    "def find_details(house):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        lat = house.find('meta', property='og:latitude')['content']\n",
    "    except:\n",
    "        lat=None\n",
    "    try:\n",
    "        long = house.find('meta', property='og:longitude')['content'] \n",
    "    except:\n",
    "        long=None\n",
    "    try:    \n",
    "        address = house.find('span', class_='address heading').text \n",
    "    except:\n",
    "        address=None\n",
    "    \n",
    "    #Property Details\n",
    "    try:\n",
    "        details = house.find('ul', class_='detail-list')\n",
    "    except:\n",
    "        details = None\n",
    "    try:\n",
    "        add_details = details.find_all('li')\n",
    "    except:\n",
    "        add_details = None\n",
    "    \n",
    "    try:\n",
    "        prop_type = add_details[0].find('span', itemprop='name').text\n",
    "    except:\n",
    "        prop_type=None\n",
    "    try:\n",
    "        rooms = add_details[1].find('span', itemprop='description').text\n",
    "    except:\n",
    "        rooms=None\n",
    "    try:\n",
    "        home_size_p = details.find('span', itemprop='name', text='Home Size').parent\n",
    "        home_size = home_size_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        home_size=''\n",
    "    try:                                                              \n",
    "        home_unit = home_size_p.find('span', itemprop='unitText').text\n",
    "    except:\n",
    "        home_unit=''\n",
    "    try:\n",
    "        lot_size_p = details.find('span', itemprop='name', text='Lot Size').parent\n",
    "        lot_size = lot_size_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        lot_size=''\n",
    "    try:                                                             \n",
    "        lot_unit = lot_size_p.find('span', itemprop='unitText').text\n",
    "    except:\n",
    "        lot_unit=''\n",
    "    try:\n",
    "        year_built_p = details.find('span', itemprop='description', text='Built in').parent\n",
    "        year_built = year_built_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        year_built=None\n",
    "    try:\n",
    "        parcel_p = details.find('span', itemprop='name', text='Parcel Number').parent\n",
    "        parcel = parcel_p.find('span', itemprop='propertyID').text\n",
    "    except:\n",
    "        parcel=None\n",
    "    try:\n",
    "        realty_p = details.find('span', itemprop='name', text='RealtyTrac Property ID').parent\n",
    "        realty = realty_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        realty=None\n",
    "    try:\n",
    "        county_p = details.find('span', itemprop='name', text='County').parent\n",
    "        county = county_p.find('span', itemprop='description').text\n",
    "    except:\n",
    "        county=None\n",
    "    try:\n",
    "        sub_p = details.find('span', itemprop='name', text='Subdivision').parent\n",
    "        sub = sub_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        sub=None\n",
    "    try:\n",
    "        census_p = details.find('span', itemprop='name', text='Census').parent\n",
    "        census = census_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        census=None\n",
    "    try:\n",
    "        tract_p = details.find('span', itemprop='name', text='Tract').parent\n",
    "        tract = tract_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        tract=None\n",
    "    try:\n",
    "        zoning = details.find_all('li')[-2].text\n",
    "    except:\n",
    "        zoning=None\n",
    "    try:                                                             \n",
    "        lot_p = details.find('span', itemprop='name', text='Lot').parent\n",
    "        lot = lot_p.find('span', itemprop='value').text\n",
    "    except:\n",
    "        lot = None\n",
    "    \n",
    "    \n",
    "    #Sales History\n",
    "    try:\n",
    "        sales = house.find('section', id='occupancy-link') \n",
    "    except:\n",
    "        sales = None\n",
    "    \n",
    "    try:                                                              \n",
    "        sale_price = sales.find('label', attrs={'for':'PurchasePrice'}).parent.parent.find('td', class_='col2').text            \n",
    "    except:\n",
    "        sale_price=None\n",
    "    try:\n",
    "        date = sales.find('label', attrs={'for':'PurchaseDate'}).parent.parent.find('td', class_='col2').text\n",
    "    except:\n",
    "        date=None\n",
    "    \n",
    "    #Estimated Value\n",
    "    try:\n",
    "        est = house.find('div', class_='rate-row access')\n",
    "    except:\n",
    "        est = None\n",
    "    \n",
    "    try:                                                              \n",
    "        estimate = est.find('strong', class_='price').text\n",
    "    except:\n",
    "        estimate= None\n",
    "    \n",
    "    #Home Disclosures\n",
    "    try:\n",
    "        disc = house.find('div', id=\"collapsePropertyHomeDisclosuresArea\")\n",
    "    except:\n",
    "        disc = None\n",
    "    \n",
    "    try:\n",
    "        sex_offenders = disc.find('span', class_='hd-title', text='Sex Offenders').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        sex_offenders = None\n",
    "    \n",
    "    try:\n",
    "        crime_index = disc.find('span', class_='hd-title',text='Crime Index').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        crime_index = None\n",
    "    \n",
    "    try:\n",
    "        env_hazards = disc.find('span', class_='hd-title',text='Environmental Hazards').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        env_hazards = None\n",
    "    \n",
    "    try:\n",
    "        natural_disasters = disc.find('span', class_='hd-title', text = 'Natural Disasters').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        natural_disasters = None\n",
    "    try:\n",
    "        school_index = disc.find('span', class_='hd-title', text = 'Local Schools').parent.find('span', class_='hd-label').text\n",
    "    except:\n",
    "        school_index = None\n",
    "    \n",
    "    try:\n",
    "        url = house.find('meta', property='og:url')['content']\n",
    "    except:\n",
    "        url=None\n",
    "    #Create the df to be returned\n",
    "    details_df = pd.DataFrame({\n",
    "        \n",
    "                       'latitude': [lat],\n",
    "                       'longitude': [long],\n",
    "                       'address':[address],\n",
    "                       'property_type': [prop_type],\n",
    "                       'rooms': [rooms],\n",
    "                       'home_size': [home_size+home_unit],\n",
    "                       'lot_size': [lot_size+lot_unit],\n",
    "                       'year_built': [year_built],\n",
    "                       'parcel_number': [parcel],\n",
    "                       'realtyID': [realty],\n",
    "                       'county': [county],\n",
    "                       'subdivision': [sub],\n",
    "                       'census': [census],\n",
    "                       'tract': [tract],\n",
    "                       'lot': [lot],\n",
    "                       'zoning': [zoning],\n",
    "                       'date': [date],\n",
    "                       'sale_price': [sale_price],\n",
    "                       'estimated_value': [estimate],\n",
    "                       'sex_offenders': [sex_offenders],\n",
    "                       'crime_index': [crime_index],\n",
    "                       'enviornmental_hazards': [env_hazards],\n",
    "                       'natural_disasters': [natural_disasters],\n",
    "                       'school quality': [school_index],\n",
    "                       'url': [url]\n",
    "                      })\n",
    "    \n",
    "    return details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that captures sales history data\n",
    "\n",
    "def find_sales_history(house):\n",
    "    \n",
    "    try:\n",
    "        details = house.find('ul', class_='detail-list')\n",
    "    except:\n",
    "        details = None\n",
    "   \n",
    "    try:\n",
    "        parcel_p = details.find('span', itemprop='name', text='Parcel Number').parent\n",
    "        parcel = parcel_p.find('span', itemprop='propertyID').text\n",
    "    except:\n",
    "        parcel=None\n",
    "    \n",
    "    try:\n",
    "        table = house.find('table', class_='sales-table history-table').find('tbody')\n",
    "    except:\n",
    "        table = None\n",
    "    \n",
    "    try:\n",
    "        sales = table.find_all('tr')\n",
    "    except:\n",
    "        sales = None\n",
    "    \n",
    "    if sales !=None:\n",
    "        for i in range(len(sales)):\n",
    "            try:\n",
    "                date = sales[i].find('td', class_='col-1').text\n",
    "            except:\n",
    "                date = None\n",
    "        \n",
    "            try:\n",
    "                price = sales[i].find('td', class_='col-3').text\n",
    "            except:\n",
    "                price = None\n",
    "            \n",
    "            try:\n",
    "                price_sqft = sales[i].find('td', class_='col-2').text\n",
    "            except:\n",
    "                price_sqft = None\n",
    "            \n",
    "            try:\n",
    "                source = sales[i].find('td', class_='col-5').text\n",
    "            except:\n",
    "                source = None\n",
    "            \n",
    "        \n",
    "            temp_df = pd.DataFrame({\n",
    "            \n",
    "                'parcel_number': [parcel],\n",
    "                'date': [date],\n",
    "                'price': [price],\n",
    "                'price_sqft': [price_sqft],\n",
    "                'source': [source]\n",
    "            })\n",
    "        \n",
    "            sales_history = temp_df.append(temp_df, ignore_index=True)\n",
    "        \n",
    "            return sales_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spot check \n",
    "#df = pd.DataFrame()\n",
    "#asession = AsyncHTMLSession()\n",
    "#r = await asession.get(absolute_links[16])\n",
    "#await r.html.arender()\n",
    "#response = r.html.raw_html\n",
    "#soup = BeautifulSoup(response, 'html.parser')\n",
    "#df = df.append(find_details(soup), ignore_index=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 50 properties\n",
      "Scraped 100 properties\n",
      "Scraped 150 properties\n",
      "Scraped 200 properties\n",
      "Scraped 250 properties\n",
      "Scraped 300 properties\n",
      "Scraped 350 properties\n",
      "Scraped 400 properties\n",
      "Scraped 450 properties\n",
      "Scraped 500 properties\n",
      "Scraped 550 properties\n",
      "Scraped 600 properties\n",
      "Scraped 650 properties\n",
      "Scraped 700 properties\n",
      "Scraped 750 properties\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the houses captures in absolute_links\n",
    "details = pd.DataFrame()\n",
    "sales_history  = pd.DataFrame()\n",
    "asession = AsyncHTMLSession()\n",
    "\n",
    "for i in range(len(absolute_links[2858:])):\n",
    "    r = await asession.get(absolute_links[i+2858])\n",
    "    await r.html.arender()\n",
    "    resp= r.html.raw_html\n",
    "    soup = BeautifulSoup(resp, 'html.parser')\n",
    "    details = details.append(find_details(soup), ignore_index=True)\n",
    "    sales_history = sales_history.append(find_sales_history(soup), ignore_index=True)\n",
    "    \n",
    "    if (i+1)%50 == 0:\n",
    "        details.to_csv('Data/house_data_details_scraped6.csv', index=False)\n",
    "        sales_history.to_csv('Data/house_data_saleshistory_scraped6.csv', index=False)\n",
    "        print(f'Scraped {details.shape[0]} properties')\n",
    "        asession.close()\n",
    "        asession = AsyncHTMLSession()\n",
    "    \n",
    "        \n",
    "details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "details.to_csv('Data/house_data_details_scraped5.csv', index=False)\n",
    "sales_history.to_csv('Data/house_data_saleshistory_scraped5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object AsyncHTMLSession.close at 0x11d1a5b00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Close out the session\n",
    "asession.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataframe to a csv file\n",
    "#details.to_csv('Data/house_data_details_scraped.csv', index=False)\n",
    "#sales_history.to_csv('Data/house_data_saleshistory_scraped.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
